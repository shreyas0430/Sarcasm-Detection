{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json files\n",
    "headlines = []\n",
    "sarcasm = []\n",
    "\n",
    "for line in open('./Sarcasm_Headlines_Dataset.json'):\n",
    "    x = json.loads(line)\n",
    "    headlines.append(x['headline'])\n",
    "    sarcasm.append(x['is_sarcastic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all punctuations\n",
    "puncs = '!\"#$%&()\\'*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "\n",
    "for p in puncs:\n",
    "    headlines = [hd.replace(p, \" \") for hd in headlines]\n",
    "    \n",
    "headlines = [hd.lower() for hd in headlines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "for i in range(26709):\n",
    "    headlines[i] = \" \".join([d for d in headlines[i].split() if d not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming\n",
    "stemmer = PorterStemmer()\n",
    "headlines = [\" \".join(stemmer.stem(w) for w in hd.split()) for hd in headlines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "headlines = [\" \".join(lemmatizer.lemmatize(w) for w in hd.split()) for hd in headlines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(headlines)\n",
    "X = cv.transform(headlines)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, sarcasm, train_size = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyas_204/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cs = [0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2]\n",
    "\n",
    "# predict accuracies using Logistic Regression\n",
    "acclr = []\n",
    "\n",
    "for c in cs:\n",
    "    lr = LogisticRegression(C = c)\n",
    "    lr.fit(x_train, y_train)\n",
    "    acclr.append(accuracy_score(y_test, lr.predict(x_test)))\n",
    "    \n",
    "# predict accuracies using SVM    \n",
    "accsvm = []\n",
    "    \n",
    "for c in cs:\n",
    "    lr = LinearSVC(C = c)\n",
    "    lr.fit(x_train, y_train)\n",
    "    accsvm.append(accuracy_score(y_test, lr.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies using Logistic Regression: \n",
      "[0.7841632347435418, 0.7862223886184949, 0.7897791089479596, 0.7905278921752152, 0.791463871209285, 0.791089479595657, 0.7912766754024709, 0.791089479595657]\n",
      "Accuracies using Support Vector Machines: \n",
      "[0.7865967802321228, 0.7772369898914264, 0.7744290527892175, 0.7716211156870086, 0.7691875701984275, 0.7690003743916136, 0.7669412205166605, 0.7656308498689629]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracies using Logistic Regression: \")\n",
    "print(acclr)\n",
    "print(\"Accuracies using Support Vector Machines: \")\n",
    "print(accsvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get max accuracy and use it for training \n",
    "lrc = max(acclr)\n",
    "lsvm = max(accsvm)\n",
    "\n",
    "c = acclr.index(max(lrc, lsvm))\n",
    "c /= 4\n",
    "\n",
    "lr = LogisticRegression(C = c)\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9189404221463003\n",
      "Testing accuracy: 0.7905278921752152\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: \" + str(accuracy_score(y_train, lr.predict(x_train))))\n",
    "print(\"Testing accuracy: \" + str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
